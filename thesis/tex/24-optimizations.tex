In the previous section, we discussed the background of algebraic effects and handlers as developed by Plotkin, Pretnar and Power \cite{DBLP:journals/acs/PlotkinP03, DBLP:conf/lics/PlotkinP08}. The system has been worked out and has been implemented as the Eff programming language of which the calculus has been described in the previous section. This was the first language to have effects as first class citizens \cite{pretnar2015introduction}. Algebraic effects and handlers aren't just a fancy new concept, it is quickly maturing. There is more and more adoption of algebraic effects as a practical language feature for user-defined side-effects. As language features are being adopted more and more, optimization becomes a bigger priority.

This section is a summerization of the work by Matija Pretnar et al. of which I was a co-author. This work focusses on the optimization of algebraic effect and handlers. First, we explain why optimizations of algebraic effects and handlers are needed. Afterwards, the optimizations are brievely discussed. Finally, some issues with the optimizations are given. The novelty of my thesis, while not being a solution to these issues, arises from the work done in the optimizations.

\subsection{Motivation}

Considering that multiple implementation are available, runtime performance becomes much more important. Some implementations take the form a interpreters \cite{programming, links2ocaml}. Most implementations take the form of libraries \cite{DBLP:conf/icfp/Brady13, kammar, eff2ocaml}. Most work has been towards the optimization of the runtime performance. However, in the case of Eff, there still was a performance difference of about 4400\% between the algebraic effects and hand-written code in OCaml (without algebraic effects). Another viable option was to provide an optimised compiler in order to transform the algebraic effects and handlers such that the runtime cost is avoided entirely \cite{optimization}. 

\subsection{Implementation}
There are two main ways that the optimising compiler used in order to optimise \eff code. The first is through the use of term rewriting rules, the other way is through purity aware compilation. Purity aware compilation provides a way for pure computations to have a more efficient representation, compared to the free monad representation. 

Several of the term rewriting rules that were created during the creation of the optimised compiler are given in figure~\ref{fig:rewriterules}. These rules show how terms are rewritten in order to minimize the footprint of algebraic effects and handlers.

\begin{figure}
\begin{center}
\framebox{
\begin{minipage}{0.95\columnwidth}
\textbf{Simplification}\\
\begin{mathpar}
  \inferrule[App-Fun]{
% \textit{inlinable}(x, e ,c)
  }{
    (\fun{x} c) \, v \leadsto c [v/x]
  }

%   \inferrule[Do-Ret]{
% % \textit{inlinable}(x, e ,c)
%   }{
%     \doin{x \leftarrow \ret v} c \leadsto c [v / x]
%   }


  % \inferrule[Do-Op]{
  % }{
  %   \doin{x \leftarrow (\doin{ y \leftarrow \op \,v } c_1 )} c_2 
  %   \quad\leadsto\quad
  %   \doin{y \leftarrow \op \,v} (\doin{x \leftarrow c_1} c_2)
  % }

\end{mathpar}
\textbf{Handler Reduction}
\begin{mathpar}
  % \inferrule[With-LetRec]{
  % }{
  %   \withhandle{v}{(\letrecin{f \, x = c_1} c_2)} \leadsto
  %   \letrecin{f \, x = c_1} (\withhandle{v}{c_2}) 
  % }

  \inferrule[With-Ret]{
    h = \shorthand
  }{
    \withhandle{h}{(\ret v)} \leadsto c_r[v/x]
  }

  \inferrule[With-Handled-Op]{
  \begin{array}{lr}
    h = \shorthand
  \end{array}
  }{
    \withhandle{h}{(\op \, v)} \leadsto
    c_\op[v / x, (\fun{x} c_r) / k]
  }

  \inferrule[With-Pure]{
     h = \shorthand \\
     \Gamma \vdash c : A \E \dirt \\
     \dirt \cap \ops = \emptyset
  }{
    \withhandle{h}{c} \leadsto \doin{x \leftarrow c} c_r
  }

  % \inferrule[With-Do]{
  %   h = \shorthand \\
  %   h' = \shorthand[\ret y \mapsto (\withhandle{h}{c_2})]
  % }
  %   {
  %   \withhandle{h}{(\doin{y \leftarrow c_1} c_2)} \leadsto
  %   \withhandle{h'}{c_1}
  % }
\end{mathpar}
\end{minipage}
}
\end{center}

\caption{Term Rewriting Rules \cite{optimization}}\label{fig:rewriterules}
\end{figure}

There is also function specialisation, which is a special term rewrite rule. Function specialisation is used in order to deal with seemingly non-terminating recursive functions. Any recursive function \texttt{let rec f x = cf in c} that is used (and handled) can be rewritten with the following rewrite rule: \texttt{handle f v with h $\mapsto$ let rec f' x = handle cf with h in f' v}. In other words, function specialisation is about bringing handlers inside the function definition.

The standard way to compile algebraic effect handlers with free monad representations introduces a substantial performance overhead. This is especially the case for pure computations. We want to be able to differentiate between pure and impure computations.

One important aspect are the subtyping judgements that are used to elaborate types into functions that coerce one type into another, as seen in Figure~\ref{fig:elaboration:sub}. The elaboration judgement $(\ctx \ent v : A) \leadsto E$ and $(\ctx \ent c : \C) \leadsto E$ means that any value $v$ or any computation $c$ is elaborated into an \ocaml expression $E$. The different elaboration judgements for computations can be seen in Figure~\ref{fig:elaboration:ext:c}, the laboration judgements for expressions have been omitted. Note that the rules \textsc{SubVal} and \textsc{SubComp} utilise the subtyping judgements. The rules \textsc{HandPure}, \textsc{HandImpure}, \textsc{DoPure} and \textsc{DoImpure} distinguish between pure and impure cases in order to generate the most optimal code. A pure $\ret v$ computation is translated just like the value $v$.

\begin{figure}
\begin{center}
\framebox{
\begin{minipage}{0.95\columnwidth}
\begin{mathpar}
  \inferrule[Sub-$\boolty$]{
  }{
    (\boolty \le \boolty) \leadsto (\fun{x}\,x)
  }

  \inferrule[Sub-$\intty$]{
  }{
    (\intty \le \intty) \leadsto (\fun{x}\,x)
  }

  % \inferrule[Sub-$\to$]{
  %   (A' \le A) \leadsto E_1 \\
  %   (\C \le \C') \leadsto E_2 
  % }{
  %   (A \to \C \le A' \to \C') \leadsto (\fun{f\,x}\,E_2\,(f\,(E_1\,x)))
  % }

  \inferrule[Sub-$\hto$]{
    (\C' \le \C) \leadsto E_1 \\
    (\D \le \D') \leadsto E_2 
  }{
    (\C \hto \D \le \C' \hto \D') \leadsto (\fun{h\,x}\,E_2\,(h\,(E_1\,x)))
  }

  \inferrule[Sub-$\E$-Pure]{
    (A \le A') \leadsto E 
  }{
    (A \E \emptyset \le A' \E \emptyset) \leadsto E
  }

  \inferrule[Sub-$\E$-PureImpure]{
    (A \le A') \leadsto E  \\
    \dirt' \neq \emptyset
  }{
    (A \E \emptyset \le A' \E \dirt') \leadsto (\fun{x}\,\kord{return}\,(E\,x))
  }

  \inferrule[Sub-$\E$-Impure]{
    (A \le A') \leadsto E  \\
    \dirt \subseteq \dirt' \\ \dirt \neq \emptyset
  }{
    (A \E \dirt \le A' \E \dirt') \leadsto 
    (\kord{fmap}\,E)
  }
\end{mathpar}
\end{minipage}
}
\end{center}
\caption{Subtyping induced coercions \cite{optimization}}\label{fig:elaboration:sub}
\end{figure}

% \begin{figure}
% \begin{center}
% \framebox{
% \begin{minipage}{0.95\columnwidth}
% \textbf{Values}
% \begin{mathpar}
%   \inferrule[SubVal]{
%     (\ctx \ent v \T A) \leadsto E_1 \\
%     (A \le A') \leadsto E_2
%   }{
%     (\ctx \ent v \T A') \leadsto (E_2\,E_1)
%   }

%   \inferrule[Var]{
%     (x \T A) \in \ctx
%   }{
%     (\ctx \ent x \T A) \leadsto x
%   }

%   \inferrule[Const]{
%     (\const \T A) \in \sig
%   }{
%     (\ctx \ent \const \T A) \leadsto \const
%   }

%   \inferrule[Fun]{ 
%     (\ctx, x \T A \ent c \T \C) \leadsto E
%   }{
%     (\ctx \ent \fun{x} c \T A \to \C) \leadsto (\fun{x}\,E)
%   }

%   \inferrule[HandPure]{
%     (\ctx, x \T A \ent c_r \T B \E \emptyset) \leadsto E_r
%   }{
%     (\ctx \ent \handler{\ret x \mapsto c_r} \T A \E \emptyset \hto B \E \emptyset) \leadsto (\fun{x}\,E_r)
%   }

%   \inferrule[HandImpure]{
%     (\ctx, x \T A \ent c_r \T B \E \dirt) \leadsto E_r \\
%     \Big[
%       (\op \T A_\op \to B_\op) \in \sig \qquad \\
%       (\ctx, x \T A_\op, k \T B_\op \to B \E \dirt \ent c_\op \T B \E \dirt)
%       \leadsto E_{\op}
%     \Big]_{\op \in \ops} \\
%     {E_i = \begin{cases}
%       \fun{x \, k} \comp{c_{\op_i}} & \op_i \in \ops \\
%       \fun{x \, k} \ocop_i x \ocamlbind k & \op_i \in \dirt - \ops \\
%       \fun{x \, k} \kpre{assert} \kord{false} & \text{otherwise}
%     \end{cases}}
%   }{
%     (\ctx \ent \shorthand \T A \E \dirt \cup \ops \hto B \E \dirt)
%     \\ \leadsto \kpre{handler} \{
%       \kord{return} = \fun{x} E_r; \ocop_1 = E_1; \dots; \ocop_n = E_n\}
%     \}
%   }

% \end{mathpar}
% \end{minipage}
% }
% \end{center}
% \caption{Type-\&-effect-directed purity aware compilation for expressions \cite{optimization}}\label{fig:elaboration:ext}
% \end{figure}

\begin{figure}
\begin{center}
\framebox{
\begin{minipage}{0.95\columnwidth}
\textbf{Computations}
\begin{mathpar}
  \inferrule[SubComp]{
    (\ctx \ent c \T \C) \leadsto E_1 \\
    (\C \le \C') \leadsto E_2
  }{
    (\ctx \ent c \T \C') \leadsto (E_2\,E_1)
  }

  \inferrule[App]{
    (\ctx \ent v_1 \T A \to \C) \leadsto E_1 \\
    (\ctx \ent v_2 \T A) \leadsto E_2
  }{
    (\ctx \ent v_1 \, v_2 \T \C) \leadsto (E_1\,E_2)
  }

 \inferrule[LetRec]{
    (\ctx, f \T A \to \C, x \T A \ent c_1 \T \C) \leadsto E_1 \\
    (\ctx, f \T A \to \C \ent c_2 \T \D) \leadsto E_2
  }{
    (\ctx \ent \letrecin{f \, x = c_1} c_2 \T \D) \leadsto
    (\letrecin{f\,x = E_1}\,E_2)
  }

  \inferrule[Ret]{
    (\ctx \ent v \T A) \leadsto E
  }{
    (\ctx \ent \ret v \T A \E \emptyset) \leadsto E 
  }

  \inferrule[Op]{
    (\op \T A \to B) \in \sig \\
    (\ctx \ent v \T A) \leadsto E
  }{
    (\ctx \ent \op \, v \T B \E \{\op\}) \leadsto (\ocop\,E)
  }

  \inferrule[DoPure]{
    (\ctx \ent c_1 \T A \E \emptyset) \leadsto E_1 \\
    (\ctx, x \T A \ent c_2 \T B \E \emptyset) \leadsto E_2
  }{
    (\ctx \ent \doin{x \leftarrow c_1} c_2 \T B \E \emptyset)
    \leadsto (\letin{x = E_1}\,E_2 )
  }

  \inferrule[DoImpure]{
    (\ctx \ent c_1 \T A \E \dirt) \leadsto E_1 \\
    (\ctx, x \T A \ent c_2 \T B \E \dirt) \leadsto E_2 \\ 
    \dirt \neq \emptyset
  }{
    (\ctx \ent \doin{x \leftarrow c_1} c_2 \T B \E \dirt )
    \leadsto (E_1 \ocamlbind \fun{x} E_2)
  }
  
  \inferrule[With]{
    (\ctx \ent v \T \C \hto \D) \leadsto E_1 \\
    (\ctx \ent c \T \C) \leadsto E_2
  }{
    (\ctx \ent \withhandle{v}{c} \T \D) \leadsto (E_1\,E_2)
  }

\end{mathpar}
\end{minipage}
}
\end{center}
\caption{Type-\&-effect-directed purity aware compilation for computations \cite{optimization}}\label{fig:elaboration:ext:c}
\end{figure}

The combination of the purity aware compilation and the term rewrite rules allows for near complete optimization. In principle, handlers are pushed as deep as possible within the program until they can either be removed due to them not being needed (e.g. handling a value, handling an effect that does not appear in the handler clause) or until they can be evaluated (handling an operation term that does appear in the handler clause). The purity aware compilation then makes sure that pure computations are efficiently translated to \ocaml.

\subsection{Evaluation}\label{loop}
The optimising compiler needed to be evaluated empirically with several testing programs. Evaluation happened in two stages. In the first stage, the performance of the optimizing compiler was compared against hand-written \ocaml code. In the second stage, the optimising compiler was compared against several other systems that support algebraic effects and handlers, such as Multicore OCaml.

The results were quite promising as the performance of fully optimised \eff becomes very similar to native code without algebraic effects. Comparing the performance against other systems also shows that an optimising compiler approach is consistently the fastest. 

\subsection{Limitations}\label{problems-eff}
As said in the motivation of this chapter, there are some issues with the optimizations. The main problem is that the optimising compiler of \eff is very fragile. The main reason is that the subtyping system is unclear to work with. With the implementation of \eff, every term is annotated with a type. This type also contains subtyping constraints. Term-rewrite rules work, as indicated by the name, with terms. Transforming most terms is easy. For example, under the right circumstances when \textsc{with-pure} is used, \texttt{handle c with h} is transformed into $\doin{x \leftarrow c} c_r$. The only change that occurs is the "shape" of the term, but the type remains the same.

This is not always the case. With function specialization, there is the rule \texttt{handle f v with h $\mapsto$ let rec f' x = handle cf with h in f' v}. With this term rewrite rule, a new recursive function \texttt{f'} needs to be created which is a specialization of the existing function \texttt{f}. Thus the type of \texttt{f'} needs to be correctly calculated. Calculating this type not only requires the types of the different terms, but also the subtyping constraints. It is quite easy to make mistakes and calculate the wrong type. With the wrong type, further optimizations might not be executed, or compilation might go completely wrong and cause typing errors. 

The main problem lies with the subtyping constraints and the implicit types of \eff. One possibility is to go to an explicitly typed calculus with Hindley-Milner based type inference. The effect system in such a system is based on row-typing \cite{type-directed, row, leijen2014koka}. Such an explicitly types calculus with row-based effects has been implemented in earlier research \cite{row-optimised}.  
Another possibility lies with a coercion-based system. This system is an explicitly-typed calculus for algebraic effects and handlers with support for subtyping using coercion proofs. This system uses coercion proofs in order to make the subtyping constraints an explicit element of the terms of the language. \cite{saleh2018explicit}

\subsection{Algebraic Subtyping}

When looking at different possibilities, we noticed the PhD thesis of Stephen Dolan. \cite{dolan2017algebraic}. Dolan provides a new subtyping based type system. While this system would not suffice for solving the issues with the optimizations, it does provide an interesting research direction for algebraic effects and handlers. 

Algebraic Subtyping has support for subtyping, but eliminates the disadvantage of having constraints. By using union and intersection types, subtyping constraints are explicitly coded within a type. For example, \lstinline{let twice f x = f (f x)} will be given the type: $(\beta \to \gamma) \to \alpha \to \gamma | \alpha \le \beta, \gamma \le \beta$. Algebraic subtyping will assign a different type to this term: $(\alpha \to \alpha \land \beta) \to \alpha \to \beta$. The two constraints are fully encoded within the type that the algebraic subtyping system infers. 

The advantage of utilising algebraic subtyping compared to subtyping is mainly the full elimination of the subtyping. This has the result that types become smaller in size and much more readable for users. Thus such a system would also be an advantage within the context of algebraic effects and handlers. 